{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in types and operators - exercises\n",
    "\n",
    "## Requirements\n",
    "\n",
    "For the second part of the exercises you will need the `wikipedia` package. If you installed Anaconda, you can run the following command in an empty jupyter cell (`!` runs the command in the underlying shell):\n",
    "\n",
    "    !conda install -c conda-forge wikipedia\n",
    "    \n",
    "If you are using virtualenv directly instead of Anaconda, the following command installs it in your virtualenv:\n",
    "\n",
    "    !pip install wikipedia\n",
    "\n",
    "or\n",
    "\n",
    "    !sudo pip install wikipedia\n",
    "    \n",
    "installs it system-wide on Linux systems.\n",
    "\n",
    "You are encouraged to reuse functions that you defined in earlier exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Define a function that takes a sequence as its input and returns whether the sequence is symmetric. A sequence is symmetric if it is equal to its reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_symmetric(l):\n",
    "    for i in range(len(l) // 2):\n",
    "        if l[i] != l[len(l)-i-1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# idiomatic solution\n",
    "def is_symmetric(l):\n",
    "    return all(l[i] == l[len(l)-i-1] for i in range(len(l) // 2))\n",
    "\n",
    "assert(is_symmetric([1]) == True)\n",
    "assert(is_symmetric([]) == True)\n",
    "assert(is_symmetric([1, 2, 3, 1]) == False)\n",
    "assert(is_symmetric([1, \"foo\", \"bar\", \"foo\", 1]) == True)\n",
    "assert(is_symmetric(\"abcba\") == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Define a function that takes a matrix as an input represented as a list of lists (you can assume that the input is a valid matrix). Return its transpose without changing the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(M):\n",
    "    Mt = []\n",
    "    for j in range(len(M[0])):\n",
    "        Mt.append([])\n",
    "        for i in range(len(M)):\n",
    "            Mt[-1].append(M[i][j])\n",
    "    return Mt\n",
    "\n",
    "m1 = [[1, 2, 3], [4, 5, 6]]\n",
    "m2 = [[1, 4], [2, 5], [3, 6]]\n",
    "\n",
    "assert(transpose(m1) == m2)\n",
    "assert(transpose(transpose(m1)) == m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Define a function that takes a string as its input and return a dictionary with the character frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_freq(s):\n",
    "    freq = {}\n",
    "    for c in s:\n",
    "        if c not in freq:\n",
    "            freq[c] = 0\n",
    "        freq[c] += 1\n",
    "    return freq\n",
    "    \n",
    "assert(char_freq(\"aba\") == {\"a\": 2, \"b\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Add an optional `skip_symbols` to the `char_freq` function. `skip_symbols` is the set of symbols that should be excluded from the frequence dictionary. If this argument is not specified, the function should include every symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_freq_with_skip(s, skip_symbols=None):\n",
    "    freq = {}\n",
    "    for c in s:\n",
    "        if c in skip_symbols:\n",
    "            continue\n",
    "        if c not in freq:\n",
    "            freq[c] = 0\n",
    "        freq[c] += 1\n",
    "    return freq\n",
    "    \n",
    "assert(char_freq_with_skip(\"ab.abc?\", skip_symbols=\".?\") == {\"a\": 2, \"b\": 2, \"c\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define a function that computes word frequencies in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq(s):\n",
    "    freq = {}\n",
    "    for word in s.split():\n",
    "        if word not in freq:\n",
    "            freq[word] = 0\n",
    "        freq[word] += 1\n",
    "    return freq\n",
    "\n",
    "s = \"the green tea and the black tea\"\n",
    "\n",
    "assert(word_freq(s) == {\"the\": 2, \"tea\": 2, \"green\": 1, \"black\": 1, \"and\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Define a function that counts the uppercase letters in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_upper_case(s):\n",
    "    cnt = 0\n",
    "    for c in s:\n",
    "        if c.isupper():\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "    \n",
    "assert(count_upper_case(\"A\") == 1)\n",
    "assert(count_upper_case(\"abA bcCa\") == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Define a function that takes two strings and decides whether they are anagrams. A string is an anagram of another string if its letters can be rearranged so that it equals the other string.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "abc -- bac\n",
    "aabb -- abab\n",
    "```\n",
    "\n",
    "Counter examples:\n",
    "\n",
    "```\n",
    "abc -- aabc\n",
    "abab -- aaab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anagram(s1, s2):\n",
    "    return char_freq(s1) == char_freq(s2)\n",
    "\n",
    "assert(anagram(\"abc\", \"bac\") == True)\n",
    "assert(anagram(\"aabb\", \"abab\") == True)\n",
    "assert(anagram(\"abab\", \"aaab\") == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Define a sentence splitter function that takes a string and splits it into a list of sentences. Sentences end with `.` and the new sentence must start with a whitespace (`str.isspace`) or be the end of the string. See the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_splitter(s):\n",
    "    sentences = []\n",
    "    sent = []\n",
    "    parts = s.split('.')\n",
    "    for i, part in enumerate(parts[:-1]):\n",
    "        sent.append(part)\n",
    "        if len(parts[i+1]) > 0 and parts[i+1][0].isspace():\n",
    "            sentences.append('.'.join(sent).strip())\n",
    "            sent = []\n",
    "    sentences.append('.'.join(sent).strip())\n",
    "    return sentences\n",
    "        \n",
    "assert(sentence_splitter(\"A.b. acd.\") == ['A.b', 'acd'])\n",
    "assert(sentence_splitter(\"A. b. acd.\") == ['A', 'b', 'acd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia module\n",
    "\n",
    "The following exercises use the `wikipedia` package. The basic usage is illustrated below.\n",
    "\n",
    "The documentation is available [here](https://pypi.python.org/pypi/wikipedia/).\n",
    "\n",
    "Searching for pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Budapest',\n",
       " 'The Grand Budapest Hotel',\n",
       " 'Hungarian Revolution of 1956',\n",
       " 'Budapest Ferenc Liszt International Airport',\n",
       " 'Budapest Honvéd FC',\n",
       " 'Budapest (song)',\n",
       " 'Red Sparrow',\n",
       " 'List of films shot in Budapest',\n",
       " 'Hungarian Parliament Building',\n",
       " 'Siege of Budapest']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "results = wikipedia.search(\"Budapest\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading an article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Budapest (Hungarian: [ˈbudɒpɛʃt] ( listen)) is the capital and the most populous city of Hungary, an'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = wikipedia.page(\"Budapest\")\n",
    "\n",
    "article.summary[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content attribute contains the full text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, 84317)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(article.content), len(article.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the module downloads the English Wikipedia. The language can be changed the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Budapest',\n",
       " 'Budapest (film)',\n",
       " 'Hongrie',\n",
       " 'Diourka Medveczky',\n",
       " 'Budapest (homonymie)',\n",
       " 'Budapest (chanson)',\n",
       " 'Association psychanalytique hongroise',\n",
       " 'Aéroport international de Budapest-Ferenc Liszt',\n",
       " 'The Grand Budapest Hotel',\n",
       " 'Insurrection de Budapest']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.search(\"Budapest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Budapest (prononcé [by.da.ˈpɛst] , hongrois : Budapest [ˈbu.dɒ.pɛʃt]  ; allemand : Budapest ou ancie'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_article = wikipedia.page(\"Budapest\")\n",
    "fr_article.summary[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Change the language back to English and test the package with a few other pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Download 4-5 arbitrary pages from the English Wikipedia (they should exceed 100000 characters combined) and compute the word frequencies using your previously defined function(s). Print the most common 20 words in the following format (the example is not the correct answer):\n",
    "\n",
    "```\n",
    "unintelligent <TAB>  123456\n",
    "moribund <TAB>   123451\n",
    "...\n",
    "```\n",
    "\n",
    "The words and their frequency are separated by TABS and no additional whitespace should be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\t2231\n",
      "of\t1163\n",
      "and\t1028\n",
      "in\t789\n",
      "to\t500\n",
      "a\t417\n",
      "The\t353\n",
      "is\t292\n",
      "Budapest\t272\n",
      "was\t260\n",
      "by\t219\n",
      "as\t216\n",
      "Hungarian\t203\n",
      "on\t194\n",
      "with\t187\n",
      "for\t185\n",
      "===\t160\n",
      "Soviet\t150\n",
      "were\t146\n",
      "that\t140\n"
     ]
    }
   ],
   "source": [
    "en_content = \"\"\n",
    "for title in wikipedia.search(\"Budapest\")[:5]:\n",
    "    page = wikipedia.page(title)\n",
    "    en_content += page.content\n",
    "    \n",
    "wp_word_freq = word_freq(en_content)\n",
    "\n",
    "for word, freq in sorted(wp_word_freq.items(), key=lambda x: -x[1])[:20]:\n",
    "    print(\"{}\\t{}\".format(word, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Repeat the same exercise for your native language if it denotes word boundaries with spaces. If it doesn't choose an arbitrary language other than English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\t1135\n",
      "és\t352\n",
      "az\t313\n",
      "A\t305\n",
      "==\t130\n",
      "Budapest\t124\n",
      "is\t89\n",
      "===\t75\n",
      "Az\t73\n",
      "város\t58\n",
      "főváros\t42\n",
      "pedig\t41\n",
      "között\t37\n",
      "egy\t32\n",
      "csak\t31\n",
      "már\t31\n",
      "–\t30\n",
      "is.\t29\n",
      "több\t28\n",
      "valamint\t28\n"
     ]
    }
   ],
   "source": [
    "wikipedia.set_lang(\"hu\")\n",
    "\n",
    "hu_content = \"\"\n",
    "for title in wikipedia.search(\"Budapest\")[:5]:\n",
    "    page = wikipedia.page(title)\n",
    "    hu_content += page.content\n",
    "    \n",
    "wp_word_freq = word_freq(hu_content)\n",
    "\n",
    "for word, freq in sorted(wp_word_freq.items(), key=lambda x: -x[1])[:20]:\n",
    "    print(\"{}\\t{}\".format(word, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Define a function that takes a string and returns its bigram frequencies as a dictionary.\n",
    "\n",
    "Character bigrams are pairs of subsequent characters. For example word `apple` contains the following bigrams: `ap, pp, pl, le`.\n",
    "\n",
    "They are used for language modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'ap': 1, 'pp': 1, 'pl': 1, 'le': 1})\n",
      "defaultdict(<class 'int'>, {'ap': 2, 'pp': 2, 'pl': 2, 'le': 2, 'e ': 1, ' a': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_char_bigrams(s):\n",
    "    bigrams = defaultdict(int)\n",
    "    for i in range(len(s) - 1):\n",
    "        bigram = s[i:i+2]\n",
    "        bigrams[bigram] += 1\n",
    "    return bigrams\n",
    "\n",
    "print(get_char_bigrams(\"apple\"))\n",
    "print(get_char_bigrams(\"apple apple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Using your previous English collection compute bigram frequencies.\n",
    "\n",
    "What are the 10 most common and 10 least common bigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_bigrams = get_char_bigrams(en_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e \t5035\n",
      " t\t3717\n",
      "th\t3413\n",
      "he\t3359\n",
      "s \t3278\n",
      " a\t2985\n",
      "in\t2832\n",
      "d \t2792\n",
      "n \t2697\n",
      "an\t2585\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\n",
    "    \"{}\\t{}\".format(bigram, freq) for bigram, freq in sorted(en_bigrams.items(), key=lambda x: -x[1])[:10]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least common bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( \t1\n",
      "))\t1\n",
      "(€\t1\n",
      "€1\t1\n",
      "CD\t1\n",
      "DT\t1\n",
      "“B\t1\n",
      "t”\t1\n",
      "lá\t1\n",
      "/L\t1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(\n",
    "    \"{}\\t{}\".format(bigram, freq) for bigram, freq in sorted(en_bigrams.items(), key=lambda x: x[1])[:10]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\*3.5 Define a function that takes two parameters: a string and an integer N and returns the N-gram frequencies of the string. For $N=2$ the function works the same as in the previous example.\n",
    "\n",
    "Try the function for $N=1..5$. How many unique N-grams are in your collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique 1-grams is 141\n",
      "The number of unique 2-grams is 2099\n",
      "The number of unique 3-grams is 10852\n",
      "The number of unique 4-grams is 30017\n",
      "The number of unique 5-grams is 55197\n"
     ]
    }
   ],
   "source": [
    "def get_n_grams(text, N):\n",
    "    freqs = {}\n",
    "    for i in range(len(text) - N + 1):\n",
    "        ngram = text[i:i+N]\n",
    "        freqs.setdefault(ngram, 0)\n",
    "        freqs[ngram] += 1\n",
    "    return freqs\n",
    "\n",
    "for n in range(1, 6):\n",
    "    ngram_freqs = get_n_grams(en_content, n)\n",
    "    print(\"The number of unique {}-grams is {}\".format(n, len(ngram_freqs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Compute the same statistics for your native language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique 1-grams is 113\n",
      "The number of unique 2-grams is 1952\n",
      "The number of unique 3-grams is 10695\n",
      "The number of unique 4-grams is 26182\n",
      "The number of unique 5-grams is 42078\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 6):\n",
    "    ngram_freqs = get_n_grams(hu_content, n)\n",
    "    print(\"The number of unique {}-grams is {}\".format(n, len(ngram_freqs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
